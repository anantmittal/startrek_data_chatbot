{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstrate Seq2Seq Wrapper with twitter chat log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d944f358a597>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# preprocessed data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstartrek\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# preprocessed data\n",
    "from startrek import data\n",
    "import data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data from pickle and npy files\n",
    "metadata, idx_q, idx_a = data.load_data(PATH='startrek/')\n",
    "(trainX, trainY), (testX, testY), (validX, validY) = data_utils.split_dataset(idx_q, idx_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters \n",
    "xseq_len = trainX.shape[-1]\n",
    "yseq_len = trainY.shape[-1]\n",
    "batch_size = 16\n",
    "xvocab_size = len(metadata['idx2w'])  \n",
    "yvocab_size = xvocab_size\n",
    "emb_dim = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seq2seq_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'seq2seq_wrapper' from '/Users/zoews/Desktop/chatbotSI650/seq2seq_wrapper.py'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(seq2seq_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<log> Building Graph </log>"
     ]
    }
   ],
   "source": [
    "model = seq2seq_wrapper.Seq2Seq(xseq_len=xseq_len,\n",
    "                               yseq_len=yseq_len,\n",
    "                               xvocab_size=xvocab_size,\n",
    "                               yvocab_size=yvocab_size,\n",
    "                               ckpt_path='ckpt/startrek/',\n",
    "                               emb_dim=emb_dim,\n",
    "                               num_layers=3\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_batch_gen = data_utils.rand_batch_gen(validX, validY, 256)\n",
    "test_batch_gen = data_utils.rand_batch_gen(testX, testY, 256)\n",
    "train_batch_gen = data_utils.rand_batch_gen(trainX, trainY, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<log> Training started </log>\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n"
     ]
    }
   ],
   "source": [
    "sess = model.train(train_batch_gen, val_batch_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = model.restore_last_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 20)\n"
     ]
    }
   ],
   "source": [
    "input_ = test_batch_gen.__next__()[0]\n",
    "output = model.predict(sess, input_)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q : [this is the unk version of im making unk a month working from home and you can too pathetic unk]; a : [laws]\n",
      "q : [hey stop reading my tweets and ignoring my emails ]; a : []\n",
      "q : [id be totally fine with it if people like trump and big corporations at least paid the same unk]; a : [analysis analysis]\n",
      "q : [i made a rude reply to this announcement earlier but im pretty excited about these rumors good luck o]; a : [reminded]\n",
      "q : [cnn fbi has discovered attempted unk of voter registration sites in more than a dozen states law enforcement officials]; a : [pull]\n",
      "q : [in summary claimed putin trolls started  this was proven totally fake now shes unk down amp has gone nuts]; a : [sucked hey cousins cousins cousins cousins cousins cousins cousins cousins]\n",
      "q : [i think most women know that hill is no champion for women amp can see what a phony she is]; a : [minimum designers coach coach coach coach coach coach coach coach coach i i i i i i i i i]\n",
      "q : [a man just unk open his door and hit my car mirror while i was sitting the car]; a : [the]\n",
      "q : [ hillary clinton was unk but only one candidate did enough to win new voters at the debate]; a : [responded]\n",
      "q : [this is the plus no you said 7 so im wondering where the hell this is in mine lol]; a : [wire oppose]\n",
      "q : [this makes me feel like im losing my mind the edge he was a unk unk unk fool it was]; a : [depressing depressing]\n",
      "q : [are unk unk issues normally in public safety unk or just this time so that unk can unk it]; a : [assistance]\n",
      "q : [i have class in 12 hours and im worried im not gonna be unk enough to make it]; a : [shield]\n",
      "q : [dont even really talk about the 3rd party candidates dont give them a platform which i think is bs]; a : [roll roll]\n",
      "q : [question are they selling seats from turner field if so does anyone know where i can find them]; a : [caused]\n",
      "q : [if your unk response to police brutality is they shouldve just listened unk etc im gonna assume youre uneducated]; a : [teeth]\n",
      "q : [well now theyre saying that i not only won the nbc presidential forum but last night the big debate nice]; a : [pleased less less connections anime anime anime anime anime digital digital digital digital digital digital]\n",
      "q : [maybe im wrong trump is winning every online debate poll i looked at about a dozen even on unk sites]; a : [org mood perfectly perfectly]\n",
      "q : [the workout playlist just took a turn i used this as entrance music for a high school wrestling match unk]; a : [giveaway nvm]\n",
      "q : [said the gop for unk im a republican and believe it or not not a racist unk statements r idiotic]; a : [airport actor]\n",
      "q : [is it safe to start unk jackson and reed together i have unk unk and unk unk as well unk]; a : [up]\n",
      "q : [son be lit 247 rt  wish i can hang with dan unk for at least one month]; a : [including]\n",
      "q : [ah okay thanks i just read 10 feel like thats unk and not rich who we see at the end]; a : [trumps trumps]\n",
      "q : [its nice walking around town with my guy friends at work because im never walking closest to the street]; a : [unlock goodies]\n",
      "q : [my perfect date play background music to my daily unk such as crying and staring at my bank account]; a : [nothing]\n",
      "q : [yeah its too bad youre stuck in the past we were supposed to move unk but you wouldnt let us]; a : [making de de advertising advertising affect]\n",
      "q : [the media got it wrong unk the unk unk of his immigration speech trump did unk unk his position]; a : [mental]\n",
      "q : [also unk doesnt exactly describe this unk you bought tickets to see three bands play and so you shall]; a : [deeply]\n",
      "q : [unk this out the unk tail is in unk like i said it is the unk of gods strength]; a : [divided]\n",
      "q : [between the unk shake and aggressive forces on the body seems like a good unk definitely worth unk]; a : [levels]\n",
      "q : [thats a joke of the week but not a unk mistake he didnt put the pool on his way ]; a : [expect]\n",
      "q : [gary johnson believes there should be unlimited campaign unk so all the money unk want to spend buying elections unk]; a : [up up up coast coast coast coast]\n",
      "q : [were always here for you and want you feeling the  dm us and lets chat some more unk]; a : [aaron asks]\n",
      "q : [it is a unk dirty unk thing that trump is doing to many of our fellow citizens sad]; a : [hunt]\n",
      "q : [i drive past a unk daily but dont stop i will have to stop tomorrow because you never know]; a : [wow]\n",
      "q : [people are unk at unk for taking over small unk water supply we must stop the bottle water practice]; a : [banner]\n",
      "q : [status my stay here unk set at one week depends what they find tomorrow unk to check whats up]; a : [depending]\n",
      "q : [hello sarah weve now found someone for the job but thank you so much for getting in touch with us]; a : [debate debate chuck chuck chuck chuck chuck chuck chuck chuck chuck chuck delayed delayed delayed er er er profit profit]\n",
      "q : [i couldnt help but laugh she ordered chicken unk i had the full unk unk w the unk on]; a : [mood]\n",
      "q : [watching this xoxo movie i am 3 minutes in and already unk why must mainstream media ruin everything ]; a : [stolen]\n",
      "q : [do you actually give a shit about these murders or are just using them to make an unk political point]; a : [magic magic websites websites websites websites el el el el el el el el el]\n",
      "q : [rt amp follow 1 of 5 4 pc travel unk open to amp winner will be announced tomorrow]; a : [mercy]\n"
     ]
    }
   ],
   "source": [
    "replies = []\n",
    "for ii, oi in zip(input_.T, output):\n",
    "    q = data_utils.decode(sequence=ii, lookup=metadata['idx2w'], separator=' ')\n",
    "    decoded = data_utils.decode(sequence=oi, lookup=metadata['idx2w'], separator=' ').split(' ')\n",
    "    if decoded.count('unk') == 0:\n",
    "        if decoded not in replies:\n",
    "            print('q : [{0}]; a : [{1}]'.format(q, ' '.join(decoded)))\n",
    "            replies.append(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
